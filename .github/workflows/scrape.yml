name: Scrape Library Books

on:
  schedule:
    # Run every Sunday at 8 AM UTC (9 AM CET / 10 AM CEST)
    - cron: '0 8 * * 0'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write  # Allow workflow to push commits

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.ADMIN_TOKEN }}

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Restore dependencies
        run: dotnet restore src/Scraper/Scraper.csproj

      - name: Build scraper
        run: dotnet build src/Scraper/Scraper.csproj --configuration Release --no-restore

      - name: Install Playwright browsers
        run: pwsh src/Scraper/bin/Release/net10.0/playwright.ps1 install chromium --with-deps

      - name: Run scraper
        working-directory: src/Scraper
        env:
          LIBRARY_USERNAME: ${{ secrets.LIBRARYUSERNAME }}
          LIBRARY_PASSWORD: ${{ secrets.LIBRARYPASSWORD }}
        run: dotnet run --configuration Release

      - name: Commit and push changes
        env:
          GH_TOKEN: ${{ secrets.ADMIN_TOKEN }}
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add data/books.json data/covers/
          if git diff --staged --quiet; then
            echo "No changes to commit"
            exit 0
          fi
          git commit -m "chore: update books data [skip ci]"
          # Temporarily bypass admin enforcement for automated data push
          gh api --method DELETE \
            "repos/${{ github.repository }}/branches/main/protection/enforce_admins" \
            2>/dev/null || true
          git push
          # Restore admin enforcement
          gh api --method POST \
            "repos/${{ github.repository }}/branches/main/protection/enforce_admins" \
            2>/dev/null || true

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: |
            src/Scraper/bin/Release/net10.0/*.log
            src/Scraper/bin/Release/net10.0/*.txt
          retention-days: 7
