name: Scrape Library Books

on:
  schedule:
    # Run every Sunday at 8 AM UTC (9 AM CET / 10 AM CEST)
    - cron: '0 8 * * 0'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write
  pull-requests: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.ADMIN_TOKEN }}

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Restore dependencies
        run: dotnet restore src/Scraper/Scraper.csproj

      - name: Build scraper
        run: dotnet build src/Scraper/Scraper.csproj --configuration Release --no-restore

      - name: Install Playwright browsers
        run: pwsh src/Scraper/bin/Release/net10.0/playwright.ps1 install chromium --with-deps

      - name: Run scraper
        working-directory: src/Scraper
        env:
          LIBRARY_USERNAME: ${{ secrets.LIBRARYUSERNAME }}
          LIBRARY_PASSWORD: ${{ secrets.LIBRARYPASSWORD }}
        run: dotnet run --configuration Release

      - name: Commit and push changes
        env:
          GH_TOKEN: ${{ secrets.ADMIN_TOKEN }}
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add data/books.json data/covers/
          if git diff --staged --quiet; then
            echo "No changes to commit"
            exit 0
          fi
          BRANCH="auto/update-books-data"
          git checkout -b "$BRANCH"
          git commit -m "chore: update books data"
          git push --force origin "$BRANCH"
          EXISTING_PR=$(gh pr list --head "$BRANCH" --base main --state open --json number --jq '.[0].number')
          if [ -z "$EXISTING_PR" ]; then
            gh pr create \
              --title "chore: update books data" \
              --body "Automated weekly book data update from library scraper." \
              --head "$BRANCH" \
              --base main
          fi
          gh pr merge "$BRANCH" --auto --merge

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: |
            src/Scraper/bin/Release/net10.0/*.log
            src/Scraper/bin/Release/net10.0/*.txt
          retention-days: 7
