name: Scrape Library Books

on:
  schedule:
    # Run every Sunday at 8 AM UTC (9 AM CET / 10 AM CEST)
    - cron: '0 8 * * 0'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Restore dependencies
        run: dotnet restore src/Scraper/Scraper.csproj

      - name: Build scraper
        run: dotnet build src/Scraper/Scraper.csproj --configuration Release --no-restore

      - name: Install Playwright browsers
        run: pwsh src/Scraper/bin/Release/net10.0/playwright.ps1 install chromium --with-deps

      - name: Run scraper
        working-directory: src/Scraper
        env:
          LIBRARY_USERNAME: ${{ secrets.LIBRARY_USERNAME }}
          LIBRARY_PASSWORD: ${{ secrets.LIBRARY_PASSWORD }}
        run: dotnet run --configuration Release

      - name: Commit and push changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add data/books.json
          git diff --staged --quiet || git commit -m "chore: update books data [skip ci]"
          git push

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: |
            src/Scraper/bin/Release/net10.0/*.log
            src/Scraper/bin/Release/net10.0/*.txt
          retention-days: 7
